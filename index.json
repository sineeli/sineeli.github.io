[{"content":"\u003ch1 id=\"object-detection-using-tensorflow-and-roboflow\"\u003eObject Detection Using TensorFlow and Roboflow\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eObject detection is a crucial task in computer vision, allowing machines to identify and locate objects within images. In this tutorial, weâ€™ll walk through the process of building an object detection model using TensorFlow and Roboflow, a platform that simplifies dataset management.\u003c/p\u003e\n\u003ch2 id=\"install-tensorflow-model-garden-package-tf-models-official\"\u003eInstall TensorFlow Model Garden Package (tf-models-official)\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epip install -U tf-models-official\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"import-necessary-libraries\"\u003eImport Necessary Libraries\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e os\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pprint\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e tempfile\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e numpy \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e np\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e tensorflow \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e tf\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e plt\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e PIL \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e Image\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e six \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e BytesIO\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e urllib.request \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e urlopen\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e official.core \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e exp_factory\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e official.core \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e task_factory\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e official.core \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e train_lib\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e official.vision.ops.preprocess_ops \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e resize_and_crop_image\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e official.vision.dataloaders.tf_example_decoder \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e TfExampleDecoder\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e official.vision.utils.object_detection \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e visualization_utils\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e official.vision.serving \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e export_saved_model_lib\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epp \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pprint\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ePrettyPrinter(indent\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e) \u003cspan style=\"color:#75715e\"\u003e# Set Pretty Print Indentation\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e__version__) \u003cspan style=\"color:#75715e\"\u003e# Check the version of tensorflow used\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003e%\u003c/span\u003ematplotlib inline\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"dataset-preparation\"\u003eDataset Preparation\u003c/h2\u003e\n\u003cp\u003eWe start by obtaining a dataset from Roboflow, which contains images and corresponding annotations. The dataset is then split into training and validation sets. We convert these datasets into the TFRecord format, a preferred format for TensorFlow.\u003c/p\u003e\n\u003ch3 id=\"download-the-car-number-plates-dataset\"\u003eDownload the Car Number Plates Dataset\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003erobofolow_dataset \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tempfile.mkdtemp\u003cspan style=\"color:#f92672\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecurl -L \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;https://universe.roboflow.com/ds/DwPgoftzcM?key=2ruB4KoWty\u0026#34;\u003c/span\u003e \u0026gt; /tmp/roboflow.zip \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eunzip -q -o /tmp/roboflow.zip -d \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003erobofolow_dataset\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003erm /tmp/roboflow.zip\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"generate-train-tfrecords\"\u003eGenerate Train TFRecords\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eOUTPUT_TF_RECORDS_DIR \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tempfile.mkdtemp\u003cspan style=\"color:#f92672\"\u003e()\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eTRAIN_DATA_DIR \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e f\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;{robofolow_dataset}/train\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eTRAIN_ANNOTATION_FILE_DIR \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e f\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;{robofolow_dataset}/train/_annotations.coco.json\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eoutput_tfrecord_train1 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os.path.join\u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    OUTPUT_TF_RECORDS_DIR, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;train\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Need to provide\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e# 1. image_dir: where images are present\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e# 2. object_annotations_file: where annotations are listed in json format\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e# 3. output_file_prefix: where to write output converted TFRecords files\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epython -m official.vision.data.create_coco_tf_record --logtostderr \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --image_dir\u003cspan style=\"color:#f92672\"\u003e={\u003c/span\u003eTRAIN_DATA_DIR\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --object_annotations_file\u003cspan style=\"color:#f92672\"\u003e={\u003c/span\u003eTRAIN_ANNOTATION_FILE_DIR\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --output_file_prefix\u003cspan style=\"color:#f92672\"\u003e={\u003c/span\u003eoutput_tfrecord_train1\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --num_shards\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"generate-validation-tfrecords\"\u003eGenerate Validation TFRecords\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eVALID_DATA_DIR \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e f\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;{robofolow_dataset}/valid\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eVALID_ANNOTATION_FILE_DIR \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e f\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;{robofolow_dataset}/valid/_annotations.coco.json\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eoutput_tfrecord_valid1 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os.path.join\u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    OUTPUT_TF_RECORDS_DIR, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;valid\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Need to provide\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e# 1. image_dir: where images are present\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e# 2. object_annotations_file: where annotations are listed in json format\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#75715e\"\u003e# 3. output_file_prefix: where to write output converted TFRecords files\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epython -m official.vision.data.create_coco_tf_record --logtostderr \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --image_dir\u003cspan style=\"color:#f92672\"\u003e={\u003c/span\u003eVALID_DATA_DIR\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --object_annotations_file\u003cspan style=\"color:#f92672\"\u003e={\u003c/span\u003eVALID_ANNOTATION_FILE_DIR\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --output_file_prefix\u003cspan style=\"color:#f92672\"\u003e={\u003c/span\u003eoutput_tfrecord_valid1\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --num_shards\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"display-a-batch-of-train-dataset\"\u003eDisplay a Batch of Train Dataset\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etf_example_decoder \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e TfExampleDecoder()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eshow_batch\u003c/span\u003e(raw_records, num_of_examples):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efigure(figsize\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e20\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e20\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    use_normalized_coordinates\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    min_score_thresh \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.30\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i, serialized_example \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e enumerate(raw_records):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esubplot(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e, i \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        decoded_tensors \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf_example_decoder\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edecode(serialized_example)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e decoded_tensors[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;image\u0026#39;\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eastype(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;uint8\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        scores \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eones(shape\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(len(decoded_tensors[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;groundtruth_boxes\u0026#39;\u003c/span\u003e])))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        visualization_utils\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evisualize_boxes_and_labels_on_image_array(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            image,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            decoded_tensors[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;groundtruth_boxes\u0026#39;\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy(),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            decoded_tensors[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;groundtruth_classes\u0026#39;\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eastype(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;int\u0026#39;\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            scores,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            category_index\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003ecategory_index,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            use_normalized_coordinates\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003euse_normalized_coordinates,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            max_boxes_to_draw\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e200\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            min_score_thresh\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003emin_score_thresh,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            agnostic_mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            instance_masks\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eNone\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            line_thickness\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eimshow(image)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eaxis(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;off\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etitle(\u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Image-\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003ei\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eplt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshow()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ebuffer_size \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e20\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003enum_of_examples \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eraw_records \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edata\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eTFRecordDataset(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e       tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eio\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egfile\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eglob(OUTPUT_TF_RECORDS_DIR \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;/train*\u0026#39;\u003c/span\u003e))\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshuffle(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        buffer_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003ebuffer_size)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etake(num_of_examples)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eshow_batch(raw_records, num_of_examples)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"model-configuration\"\u003eModel Configuration\u003c/h2\u003e\n\u003cp\u003eFor our object detection model, we choose the RetinaNet architecture with a ResNet backbone. We configure the model, specifying the number of classes, anchor sizes, and input dimensions. Transfer learning is employed by initializing the model with pre-trained weights.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e exp_factory\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eget_exp_config(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;retinanet_resnetfpn_coco\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"download-the-resnet-50-backbone\"\u003eDownload the ResNet-50 Backbone\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eckpt_dir \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tempfile.mkdtemp\u003cspan style=\"color:#f92672\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ewget \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;https://storage.googleapis.com/tf_model_garden/vision/retinanet/retinanet-resnet50fpn.tar.gz\u0026#34;\u003c/span\u003e -P \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/tmp/\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etar -xvzf \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/tmp/retinanet-resnet50fpn.tar.gz\u0026#34;\u003c/span\u003e -C \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003eckpt_dir\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003erm \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;/tmp/retinanet-resnet50fpn.tar.gz\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"training-configuration\"\u003eTraining Configuration\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eBATCH_SIZE \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eepochs \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e5\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eIMG_SIZE \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e640\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esteps_per_epoch \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e NUM_TRAIN_EXAMPLES \u003cspan style=\"color:#f92672\"\u003e//\u003c/span\u003e BATCH_SIZE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003evalidation_steps \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e NUM_VAL_EXAMPLES \u003cspan style=\"color:#f92672\"\u003e//\u003c/span\u003e BATCH_SIZE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003enum_train_steps \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e steps_per_epoch \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e epochs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ewarmup_steps \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e int(\u003cspan style=\"color:#ae81ff\"\u003e0.1\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e num_train_steps)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einitial_learning_rate \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.01\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ewarmup_learning_rate \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.5\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e initial_learning_rate\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Runtime configuration\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eruntime\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emixed_precision_dtype \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;bfloat16\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# exp_config.runtime.num_gpus = 1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Task Level configuration\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einit_checkpoint \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(ckpt_dir, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;ckpt-33264\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einit_checkpoint_modules \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;backbone\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efreeze_backbone \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eannotation_file \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Model configuration\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enum_classes \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eanchor\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eanchor_size \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e4.0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eanchor\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003easpect_ratios \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [\u003cspan style=\"color:#ae81ff\"\u003e0.5\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e1.0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e1.5\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e2.0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e2.5\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e3.0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e4.0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e5.0\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einput_size \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [IMG_SIZE, IMG_SIZE, \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Train data configuration\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrain_data\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einput_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(OUTPUT_TF_RECORDS_DIR, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;train*\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrain_data\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eglobal_batch_size \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e BATCH_SIZE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrain_data\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edtype \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;float32\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Validation data configuration\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalidation_data\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einput_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(OUTPUT_TF_RECORDS_DIR, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;val*\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrain_data\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eglobal_batch_size \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e BATCH_SIZE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalidation_data\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edtype \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;float32\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# Trainer configuration\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003echeckpoint_interval \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e steps_per_epoch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizer_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewarmup\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elinear\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewarmup_steps \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e steps_per_epoch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizer_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewarmup\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elinear\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewarmup_learning_rate \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e warmup_learning_rate\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizer_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elearning_rate\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etype \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;cosine\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizer_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elearning_rate\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecosine\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edecay_steps \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e num_train_steps\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizer_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elearning_rate\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecosine\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einitial_learning_rate \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e initial_learning_rate\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrain_steps \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e num_train_steps\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalidation_steps \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e validation_steps\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalidation_interval \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e steps_per_epoch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esteps_per_loop \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e steps_per_epoch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainer\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esummary_interval \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e steps_per_epoch\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epp\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epprint(exp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eas_dict())\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e{   \u0026#39;runtime\u0026#39;: {   \u0026#39;all_reduce_alg\u0026#39;: None,\n                   \u0026#39;batchnorm_spatial_persistent\u0026#39;: False,\n                   \u0026#39;dataset_num_private_threads\u0026#39;: None,\n                   \u0026#39;default_shard_dim\u0026#39;: -1,\n                   \u0026#39;distribution_strategy\u0026#39;: \u0026#39;mirrored\u0026#39;,\n                   \u0026#39;enable_xla\u0026#39;: False,\n                   \u0026#39;gpu_thread_mode\u0026#39;: None,\n                   \u0026#39;loss_scale\u0026#39;: None,\n                   \u0026#39;mixed_precision_dtype\u0026#39;: \u0026#39;bfloat16\u0026#39;,\n                   \u0026#39;num_cores_per_replica\u0026#39;: 1,\n                   \u0026#39;num_gpus\u0026#39;: 0,\n                   \u0026#39;num_packs\u0026#39;: 1,\n                   \u0026#39;per_gpu_thread_count\u0026#39;: 0,\n                   \u0026#39;run_eagerly\u0026#39;: False,\n                   \u0026#39;task_index\u0026#39;: -1,\n                   \u0026#39;tpu\u0026#39;: None,\n                   \u0026#39;tpu_enable_xla_dynamic_padder\u0026#39;: None,\n                   \u0026#39;use_tpu_mp_strategy\u0026#39;: False,\n                   \u0026#39;worker_hosts\u0026#39;: None},\n    \u0026#39;task\u0026#39;: {   \u0026#39;allow_image_summary\u0026#39;: False,\n                \u0026#39;annotation_file\u0026#39;: \u0026#39;\u0026#39;,\n                \u0026#39;differential_privacy_config\u0026#39;: None,\n                \u0026#39;export_config\u0026#39;: {   \u0026#39;cast_detection_classes_to_float\u0026#39;: False,\n                                     \u0026#39;cast_num_detections_to_float\u0026#39;: False,\n                                     \u0026#39;output_intermediate_features\u0026#39;: False,\n                                     \u0026#39;output_normalized_coordinates\u0026#39;: False},\n                \u0026#39;freeze_backbone\u0026#39;: True,\n                \u0026#39;init_checkpoint\u0026#39;: \u0026#39;/tmp/tmp4sm_f79o/ckpt-33264\u0026#39;,\n                \u0026#39;init_checkpoint_modules\u0026#39;: \u0026#39;backbone\u0026#39;,\n                \u0026#39;losses\u0026#39;: {   \u0026#39;box_loss_weight\u0026#39;: 50,\n                              \u0026#39;focal_loss_alpha\u0026#39;: 0.25,\n                              \u0026#39;focal_loss_gamma\u0026#39;: 1.5,\n                              \u0026#39;huber_loss_delta\u0026#39;: 0.1,\n                              \u0026#39;l2_weight_decay\u0026#39;: 0.0001,\n                              \u0026#39;loss_weight\u0026#39;: 1.0},\n                \u0026#39;max_num_eval_detections\u0026#39;: 100,\n                \u0026#39;model\u0026#39;: {   \u0026#39;anchor\u0026#39;: {   \u0026#39;anchor_size\u0026#39;: 4.0,\n                                           \u0026#39;aspect_ratios\u0026#39;: [   0.5,\n                                                                1.0,\n                                                                1.5,\n                                                                2.0,\n                                                                2.5,\n                                                                3.0,\n                                                                4.0,\n                                                                5.0],\n                                           \u0026#39;num_scales\u0026#39;: 3},\n                             \u0026#39;backbone\u0026#39;: {   \u0026#39;resnet\u0026#39;: {   \u0026#39;bn_trainable\u0026#39;: True,\n                                                           \u0026#39;depth_multiplier\u0026#39;: 1.0,\n                                                           \u0026#39;model_id\u0026#39;: 50,\n                                                           \u0026#39;replace_stem_max_pool\u0026#39;: False,\n                                                           \u0026#39;resnetd_shortcut\u0026#39;: False,\n                                                           \u0026#39;scale_stem\u0026#39;: True,\n                                                           \u0026#39;se_ratio\u0026#39;: 0.0,\n                                                           \u0026#39;stem_type\u0026#39;: \u0026#39;v0\u0026#39;,\n                                                           \u0026#39;stochastic_depth_drop_rate\u0026#39;: 0.0},\n                                             \u0026#39;type\u0026#39;: \u0026#39;resnet\u0026#39;},\n                             \u0026#39;decoder\u0026#39;: {   \u0026#39;fpn\u0026#39;: {   \u0026#39;fusion_type\u0026#39;: \u0026#39;sum\u0026#39;,\n                                                       \u0026#39;num_filters\u0026#39;: 256,\n                                                       \u0026#39;use_keras_layer\u0026#39;: False,\n                                                       \u0026#39;use_separable_conv\u0026#39;: False},\n                                            \u0026#39;type\u0026#39;: \u0026#39;fpn\u0026#39;},\n                             \u0026#39;detection_generator\u0026#39;: {   \u0026#39;apply_nms\u0026#39;: True,\n                                                        \u0026#39;max_num_detections\u0026#39;: 100,\n                                                        \u0026#39;nms_iou_threshold\u0026#39;: 0.5,\n                                                        \u0026#39;nms_version\u0026#39;: \u0026#39;v2\u0026#39;,\n                                                        \u0026#39;pre_nms_score_threshold\u0026#39;: 0.05,\n                                                        \u0026#39;pre_nms_top_k\u0026#39;: 5000,\n                                                        \u0026#39;return_decoded\u0026#39;: None,\n                                                        \u0026#39;soft_nms_sigma\u0026#39;: None,\n                                                        \u0026#39;tflite_post_processing\u0026#39;: {   \u0026#39;max_classes_per_detection\u0026#39;: 5,\n                                                                                      \u0026#39;max_detections\u0026#39;: 200,\n                                                                                      \u0026#39;nms_iou_threshold\u0026#39;: 0.5,\n                                                                                      \u0026#39;nms_score_threshold\u0026#39;: 0.1,\n                                                                                      \u0026#39;normalize_anchor_coordinates\u0026#39;: False,\n                                                                                      \u0026#39;omit_nms\u0026#39;: False,\n                                                                                      \u0026#39;use_regular_nms\u0026#39;: False},\n                                                        \u0026#39;use_class_agnostic_nms\u0026#39;: False,\n                                                        \u0026#39;use_cpu_nms\u0026#39;: False},\n                             \u0026#39;head\u0026#39;: {   \u0026#39;attribute_heads\u0026#39;: [],\n                                         \u0026#39;num_convs\u0026#39;: 4,\n                                         \u0026#39;num_filters\u0026#39;: 256,\n                                         \u0026#39;share_classification_heads\u0026#39;: False,\n                                         \u0026#39;use_separable_conv\u0026#39;: False},\n                             \u0026#39;input_size\u0026#39;: [640, 640, 3],\n                             \u0026#39;max_level\u0026#39;: 7,\n                             \u0026#39;min_level\u0026#39;: 3,\n                             \u0026#39;norm_activation\u0026#39;: {   \u0026#39;activation\u0026#39;: \u0026#39;relu\u0026#39;,\n                                                    \u0026#39;norm_epsilon\u0026#39;: 0.001,\n                                                    \u0026#39;norm_momentum\u0026#39;: 0.99,\n                                                    \u0026#39;use_sync_bn\u0026#39;: False},\n                             \u0026#39;num_classes\u0026#39;: 3},\n                \u0026#39;name\u0026#39;: None,\n                \u0026#39;per_category_metrics\u0026#39;: False,\n                \u0026#39;train_data\u0026#39;: {   \u0026#39;apply_tf_data_service_before_batching\u0026#39;: False,\n                                  \u0026#39;autotune_algorithm\u0026#39;: None,\n                                  \u0026#39;block_length\u0026#39;: 1,\n                                  \u0026#39;cache\u0026#39;: False,\n                                  \u0026#39;cycle_length\u0026#39;: None,\n                                  \u0026#39;decoder\u0026#39;: {   \u0026#39;simple_decoder\u0026#39;: {   \u0026#39;attribute_names\u0026#39;: [   ],\n                                                                       \u0026#39;mask_binarize_threshold\u0026#39;: None,\n                                                                       \u0026#39;regenerate_source_id\u0026#39;: False},\n                                                 \u0026#39;type\u0026#39;: \u0026#39;simple_decoder\u0026#39;},\n                                  \u0026#39;deterministic\u0026#39;: None,\n                                  \u0026#39;drop_remainder\u0026#39;: True,\n                                  \u0026#39;dtype\u0026#39;: \u0026#39;float32\u0026#39;,\n                                  \u0026#39;enable_shared_tf_data_service_between_parallel_trainers\u0026#39;: False,\n                                  \u0026#39;enable_tf_data_service\u0026#39;: False,\n                                  \u0026#39;file_type\u0026#39;: \u0026#39;tfrecord\u0026#39;,\n                                  \u0026#39;global_batch_size\u0026#39;: 8,\n                                  \u0026#39;input_path\u0026#39;: \u0026#39;/tmp/tmpd67ub1pe/train*\u0026#39;,\n                                  \u0026#39;is_training\u0026#39;: True,\n                                  \u0026#39;parser\u0026#39;: {   \u0026#39;aug_policy\u0026#39;: None,\n                                                \u0026#39;aug_rand_hflip\u0026#39;: True,\n                                                \u0026#39;aug_scale_max\u0026#39;: 1.2,\n                                                \u0026#39;aug_scale_min\u0026#39;: 0.8,\n                                                \u0026#39;aug_type\u0026#39;: None,\n                                                \u0026#39;match_threshold\u0026#39;: 0.5,\n                                                \u0026#39;max_num_instances\u0026#39;: 100,\n                                                \u0026#39;num_channels\u0026#39;: 3,\n                                                \u0026#39;skip_crowd_during_training\u0026#39;: True,\n                                                \u0026#39;unmatched_threshold\u0026#39;: 0.5},\n                                  \u0026#39;prefetch_buffer_size\u0026#39;: None,\n                                  \u0026#39;seed\u0026#39;: None,\n                                  \u0026#39;sharding\u0026#39;: True,\n                                  \u0026#39;shuffle_buffer_size\u0026#39;: 10000,\n                                  \u0026#39;tf_data_service_address\u0026#39;: None,\n                                  \u0026#39;tf_data_service_job_name\u0026#39;: None,\n                                  \u0026#39;tfds_as_supervised\u0026#39;: False,\n                                  \u0026#39;tfds_data_dir\u0026#39;: \u0026#39;\u0026#39;,\n                                  \u0026#39;tfds_name\u0026#39;: \u0026#39;\u0026#39;,\n                                  \u0026#39;tfds_skip_decoding_feature\u0026#39;: \u0026#39;\u0026#39;,\n                                  \u0026#39;tfds_split\u0026#39;: \u0026#39;\u0026#39;,\n                                  \u0026#39;trainer_id\u0026#39;: None,\n                                  \u0026#39;weights\u0026#39;: None},\n                \u0026#39;use_coco_metrics\u0026#39;: True,\n                \u0026#39;use_wod_metrics\u0026#39;: False,\n                \u0026#39;validation_data\u0026#39;: {   \u0026#39;apply_tf_data_service_before_batching\u0026#39;: False,\n                                       \u0026#39;autotune_algorithm\u0026#39;: None,\n                                       \u0026#39;block_length\u0026#39;: 1,\n                                       \u0026#39;cache\u0026#39;: False,\n                                       \u0026#39;cycle_length\u0026#39;: None,\n                                       \u0026#39;decoder\u0026#39;: {   \u0026#39;simple_decoder\u0026#39;: {   \u0026#39;attribute_names\u0026#39;: [   ],\n                                                                            \u0026#39;mask_binarize_threshold\u0026#39;: None,\n                                                                            \u0026#39;regenerate_source_id\u0026#39;: False},\n                                                      \u0026#39;type\u0026#39;: \u0026#39;simple_decoder\u0026#39;},\n                                       \u0026#39;deterministic\u0026#39;: None,\n                                       \u0026#39;drop_remainder\u0026#39;: True,\n                                       \u0026#39;dtype\u0026#39;: \u0026#39;float32\u0026#39;,\n                                       \u0026#39;enable_shared_tf_data_service_between_parallel_trainers\u0026#39;: False,\n                                       \u0026#39;enable_tf_data_service\u0026#39;: False,\n                                       \u0026#39;file_type\u0026#39;: \u0026#39;tfrecord\u0026#39;,\n                                       \u0026#39;global_batch_size\u0026#39;: 8,\n                                       \u0026#39;input_path\u0026#39;: \u0026#39;/tmp/tmpd67ub1pe/val*\u0026#39;,\n                                       \u0026#39;is_training\u0026#39;: False,\n                                       \u0026#39;parser\u0026#39;: {   \u0026#39;aug_policy\u0026#39;: None,\n                                                     \u0026#39;aug_rand_hflip\u0026#39;: False,\n                                                     \u0026#39;aug_scale_max\u0026#39;: 1.0,\n                                                     \u0026#39;aug_scale_min\u0026#39;: 1.0,\n                                                     \u0026#39;aug_type\u0026#39;: None,\n                                                     \u0026#39;match_threshold\u0026#39;: 0.5,\n                                                     \u0026#39;max_num_instances\u0026#39;: 100,\n                                                     \u0026#39;num_channels\u0026#39;: 3,\n                                                     \u0026#39;skip_crowd_during_training\u0026#39;: True,\n                                                     \u0026#39;unmatched_threshold\u0026#39;: 0.5},\n                                       \u0026#39;prefetch_buffer_size\u0026#39;: None,\n                                       \u0026#39;seed\u0026#39;: None,\n                                       \u0026#39;sharding\u0026#39;: True,\n                                       \u0026#39;shuffle_buffer_size\u0026#39;: 10000,\n                                       \u0026#39;tf_data_service_address\u0026#39;: None,\n                                       \u0026#39;tf_data_service_job_name\u0026#39;: None,\n                                       \u0026#39;tfds_as_supervised\u0026#39;: False,\n                                       \u0026#39;tfds_data_dir\u0026#39;: \u0026#39;\u0026#39;,\n                                       \u0026#39;tfds_name\u0026#39;: \u0026#39;\u0026#39;,\n                                       \u0026#39;tfds_skip_decoding_feature\u0026#39;: \u0026#39;\u0026#39;,\n                                       \u0026#39;tfds_split\u0026#39;: \u0026#39;\u0026#39;,\n                                       \u0026#39;trainer_id\u0026#39;: None,\n                                       \u0026#39;weights\u0026#39;: None}},\n    \u0026#39;trainer\u0026#39;: {   \u0026#39;allow_tpu_summary\u0026#39;: False,\n                   \u0026#39;best_checkpoint_eval_metric\u0026#39;: \u0026#39;\u0026#39;,\n                   \u0026#39;best_checkpoint_export_subdir\u0026#39;: \u0026#39;\u0026#39;,\n                   \u0026#39;best_checkpoint_metric_comp\u0026#39;: \u0026#39;higher\u0026#39;,\n                   \u0026#39;checkpoint_interval\u0026#39;: 122,\n                   \u0026#39;continuous_eval_timeout\u0026#39;: 3600,\n                   \u0026#39;eval_tf_function\u0026#39;: True,\n                   \u0026#39;eval_tf_while_loop\u0026#39;: False,\n                   \u0026#39;loss_upper_bound\u0026#39;: 1000000.0,\n                   \u0026#39;max_to_keep\u0026#39;: 5,\n                   \u0026#39;optimizer_config\u0026#39;: {   \u0026#39;ema\u0026#39;: None,\n                                           \u0026#39;learning_rate\u0026#39;: {   \u0026#39;cosine\u0026#39;: {   \u0026#39;alpha\u0026#39;: 0.0,\n                                                                              \u0026#39;decay_steps\u0026#39;: 610,\n                                                                              \u0026#39;initial_learning_rate\u0026#39;: 0.01,\n                                                                              \u0026#39;name\u0026#39;: \u0026#39;CosineDecay\u0026#39;,\n                                                                              \u0026#39;offset\u0026#39;: 0},\n                                                                \u0026#39;type\u0026#39;: \u0026#39;cosine\u0026#39;},\n                                           \u0026#39;optimizer\u0026#39;: {   \u0026#39;sgd\u0026#39;: {   \u0026#39;clipnorm\u0026#39;: None,\n                                                                       \u0026#39;clipvalue\u0026#39;: None,\n                                                                       \u0026#39;decay\u0026#39;: 0.0,\n                                                                       \u0026#39;global_clipnorm\u0026#39;: None,\n                                                                       \u0026#39;momentum\u0026#39;: 0.9,\n                                                                       \u0026#39;name\u0026#39;: \u0026#39;SGD\u0026#39;,\n                                                                       \u0026#39;nesterov\u0026#39;: False},\n                                                            \u0026#39;type\u0026#39;: \u0026#39;sgd\u0026#39;},\n                                           \u0026#39;warmup\u0026#39;: {   \u0026#39;linear\u0026#39;: {   \u0026#39;name\u0026#39;: \u0026#39;linear\u0026#39;,\n                                                                       \u0026#39;warmup_learning_rate\u0026#39;: 0.005,\n                                                                       \u0026#39;warmup_steps\u0026#39;: 122},\n                                                         \u0026#39;type\u0026#39;: \u0026#39;linear\u0026#39;}},\n                   \u0026#39;preemption_on_demand_checkpoint\u0026#39;: True,\n                   \u0026#39;recovery_begin_steps\u0026#39;: 0,\n                   \u0026#39;recovery_max_trials\u0026#39;: 0,\n                   \u0026#39;steps_per_loop\u0026#39;: 122,\n                   \u0026#39;summary_interval\u0026#39;: 122,\n                   \u0026#39;train_steps\u0026#39;: 610,\n                   \u0026#39;train_tf_function\u0026#39;: True,\n                   \u0026#39;train_tf_while_loop\u0026#39;: True,\n                   \u0026#39;validation_interval\u0026#39;: 122,\n                   \u0026#39;validation_steps\u0026#39;: 8,\n                   \u0026#39;validation_summary_subdir\u0026#39;: \u0026#39;validation\u0026#39;}}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"training\"\u003eTraining\u003c/h2\u003e\n\u003cp\u003eCreate the Task object (tfm.core.base_task.Task) from the config_definitions.TaskConfig.\u003c/p\u003e\n\u003cp\u003eThe Task object has all the methods necessary for building the dataset, building the model, and running training \u0026amp; evaluation. These methods are driven by tfm.core.train_lib.run_experiment.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel_dir \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tempfile\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emkdtemp()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003ewith\u003c/span\u003e distribution_strategy\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003escope():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    task \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e task_factory\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eget_task(exp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask, logging_dir\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003emodel_dir)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel, eval_logs \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e train_lib\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erun_experiment(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    distribution_strategy\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003edistribution_strategy,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    task\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etask,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;train_and_eval\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    params\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eexp_config,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    model_dir\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003emodel_dir)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"exporting-the-model\"\u003eExporting the Model\u003c/h2\u003e\n\u003cp\u003eOnce satisfied with the modelâ€™s performance, we export it for serving using TensorFlowâ€™s SavedModel format. This step prepares the model for deployment in various applications.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexport_dir \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;./model/\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexport_saved_model_lib\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexport_inference_graph(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    input_type\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;image_tensor\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    batch_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    input_image_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[IMG_SIZE, IMG_SIZE],\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    params\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eexp_config,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    checkpoint_path\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrain\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elatest_checkpoint(model_dir),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    export_dir\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eexport_dir)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"inference-on-new-images\"\u003eInference on New Images\u003c/h2\u003e\n\u003cp\u003eWe demonstrate how to use the trained model for inference on new images. The model identifies objects in these images, and we visualize the results, showcasing the modelâ€™s ability to detect and classify objects accurately.\u003c/p\u003e\n\u003ch3 id=\"load-the-exported-model\"\u003eLoad the exported model\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eimported \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esaved_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eload(export_dir)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel_fn \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e imported\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esignatures[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;serving_default\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eload_image_into_numpy_array\u003c/span\u003e(path):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;Load an image from file into a numpy array.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    Puts image into numpy array to feed into tensorflow graph.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    Note that by convention we put it into a numpy array with shape\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    (height, width, channels), where channels=3 for RGB.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    Args:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e        path: the file path to the image\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e        \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    Returns:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e        uint8 numpy array with shape (img_height, img_width, 3)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e(path\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estartswith(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;http\u0026#39;\u003c/span\u003e)):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        response \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e urlopen(path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image_data \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e response\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image_data \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e BytesIO(image_data)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Image\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eopen(image_data)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image_data \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eio\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egfile\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eGFile(path, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;rb\u0026#39;\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eread()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Image\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eopen(BytesIO(image_data))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    (im_width, im_height) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e image\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esize\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003earray(image\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egetdata())\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ereshape(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        (\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, im_height, im_width, \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e))\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eastype(np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003euint8)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ebuild_inputs_for_object_detection\u003c/span\u003e(image, input_image_size):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u0026#34;Builds Object Detection model inputs for serving.\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image, _ \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e resize_and_crop_image(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        input_image_size,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        padded_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003einput_image_size,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        aug_scale_min\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1.0\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        aug_scale_max\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1.0\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e image\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"inference-on-validation-images\"\u003eInference on Validation Images\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einput_image_size \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e (IMG_SIZE, IMG_SIZE)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eplt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efigure(figsize\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e20\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e20\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emin_score_thresh \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.4\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e# Change minimum score for threshold to see all bounding boxes confidences.\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eval_ds \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edata\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eTFRecordDataset(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eio\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003egfile\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eglob(exp_config\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etask\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalidation_data\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einput_path \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;*\u0026#39;\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i, serialized_example \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e enumerate(val_ds\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshuffle(\u003cspan style=\"color:#ae81ff\"\u003e20\u003c/span\u003e)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etake(\u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e)):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esubplot(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e, i\u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    decoded_tensors \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf_example_decoder\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edecode(serialized_example)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e build_inputs_for_object_detection(decoded_tensors[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;image\u0026#39;\u003c/span\u003e], input_image_size)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexpand_dims(image, axis\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecast(image, dtype \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003euint8)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image_np \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e image[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    result \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e model_fn(image)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    visualization_utils\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evisualize_boxes_and_labels_on_image_array(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        image_np,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        result[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;detection_boxes\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy(),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        result[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;detection_classes\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eastype(int),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        result[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;detection_scores\u0026#39;\u003c/span\u003e][\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy(),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        category_index\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003ecategory_index,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        use_normalized_coordinates\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        max_boxes_to_draw\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e200\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        min_score_thresh\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003emin_score_thresh,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        agnostic_mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        instance_masks\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eNone\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        line_thickness\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eimshow(image_np)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eaxis(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;off\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eplt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshow()\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eIn conclusion, this tutorial covered the end-to-end process of building an object detection model using TensorFlow and Roboflow. From dataset preparation to model configuration, training, and deployment, you now have a foundation to create your own custom object detection solutions.\u003c/p\u003e\n","description":"","image":"/images/Number-Plate-Detection.png","permalink":"https://sineeli.github.io/blogs/car-num-plate-detection/","title":"Car Number Plate Recognition using Tensorflow Model Garden"},{"content":"","description":"My gallery :earth_asia:","image":null,"permalink":"https://sineeli.github.io/gallery/","title":"Image Gallery"}]